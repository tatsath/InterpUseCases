# Final Feature Labels Summary: BERT vs FinBERT

## Overview
This document provides the final feature labels generated using the Delphi SAE auto-interpretation library for the top financial features from both BERT and FinBERT models.

## Key Findings

### Feature Evolution Patterns
- **Consistent Features**: Features that maintained financial specialization across both models
- **Emerging Features**: Features that became financial specialists in FinBERT but were general-purpose in BERT
- **Top Financial Features**: Features that showed the highest financial activation improvements

### Activity Patterns
- **BERT**: Most features had moderate activity (4K-40K activations)
- **FinBERT**: Much higher activity levels (13K-69K activations), showing increased specialization

## Feature Labels Comparison

| Feature | Type | BERT Label | FinBERT Label | Key Insight |
|---------|------|------------|---------------|-------------|
| 34 | Consistent Financial | Explanation could not be parsed | Various types of punctuation marks, special characters, and | Maintained focus on structural elements |
| 42 | Emerging Financial | Explanation could not be parsed | A mix of normal words and special characters, | Evolved to handle mixed content formats |
| 43 | Emerging Financial | Feature_43 | "more" is frequently used to indicate an increase | Specialized for comparative language |
| 48 | Emerging Financial | Feature_48 | Various types of data, including numbers, percentages, and | Specialized for financial data processing |
| 51 | Emerging Financial | Feature_51 | Tokens representing a news article title, with a | Specialized for news headline processing |
| 52 | Emerging Financial | Feature_52 | Market trends, company performance, and economic analysis, often | Specialized for market analysis |
| 54 | Emerging Financial | Feature_54 | Financial and business-related information, including earnings reports, stock | Specialized for earnings and stock data |
| 56 | Top Financial | Feature_56 | Texts containing quotes and phrases expressing opinions, predictions, | Specialized for sentiment and predictions |
| 59 | Emerging Financial | Feature_59 | Text snippets from various articles or documents, likely | Specialized for document processing |
| 65 | Consistent Financial | Feature_65 | A mix of numerical values, special characters, and | Maintained focus on numerical data |
| 83 | Emerging Financial | Feature_83 | Specific phrases, likely representing news headlines or article | Specialized for headline processing |
| 103 | Emerging Financial | Feature_103 | Text snippets from news articles or financial reports, | Specialized for financial news |
| 106 | Top Financial | Feature_106 | Stock market related terms and phrases, including company | Specialized for stock market terminology |
| 109 | Top Financial | Feature_109 | Phrases and sentences with varying lengths, containing a | Specialized for variable-length financial text |
| 115 | Emerging Financial | Feature_115 | Investment and stock market, with frequent mentions of | Specialized for investment content |
| 120 | Emerging Financial | Feature_120 | Year numbers with special formatting, specifically with "##" | Specialized for temporal financial data |
| 127 | Emerging Financial | Feature_127 | "after" frequently appears in the context of describing | Specialized for causal relationships |
| 133 | Top Financial | Feature_133 | Text contains various phrases and sentences with high | Specialized for high-activation content |
| 146 | Top Financial | Feature_146 | Special characters, punctuation, and tokens indicating the end | Specialized for structural markers |
| 150 | Emerging Financial | Feature_150 | Inflation data, reports, and its impact on the | Specialized for inflation analysis |
| 174 | Emerging Financial | Feature_174 | Frequent occurrences of the word "higher" in various | Specialized for upward trend analysis |
| 184 | Emerging Financial | Feature_184 | Financial and stock market related text, including stock | Specialized for general financial content |

## Key Insights

### 1. **Specialization Evolution**
- Most features evolved from general-purpose to financial-specialized
- Only 2 features (34, 65) maintained consistent financial focus
- 15 features emerged as new financial specialists in FinBERT

### 2. **Domain-Specific Patterns**
- **Market Analysis**: Features 52, 106, 115, 184 specialized for market trends and stock analysis
- **Data Processing**: Features 48, 65, 120 specialized for numerical and temporal data
- **News Processing**: Features 51, 83, 103 specialized for news headlines and articles
- **Sentiment Analysis**: Features 56, 127 specialized for opinions and causal relationships

### 3. **Activity Improvements**
- FinBERT features showed 2-10x higher activation counts compared to BERT
- Feature 103 had the highest activity (69,679 activations) in FinBERT
- Most features showed significant specialization improvements

### 4. **Language Patterns**
- **Comparative Language**: Features 43, 174 specialized for comparative terms ("more", "higher")
- **Temporal Language**: Features 120, 127 specialized for temporal and causal relationships
- **Structural Language**: Features 34, 146 specialized for punctuation and structural markers

## Technical Details

### Methodology
- Used Delphi SAE auto-interpretation library with Llama 3.1 8B model
- Analyzed 22 top financial features from both BERT and FinBERT
- Processed 1000 financial news samples for activation collection
- Generated short summaries (<10 words) and full explanations

### Data Sources
- **BERT Model**: bert-base-uncased
- **FinBERT Model**: ProsusAI/finbert
- **Dataset**: Yahoo Finance Stock Market News
- **SAE Configuration**: k=32, latents=200, layer 6

### Files Generated
- `feature_labels_comparison.csv`: Detailed comparison with full explanations
- `feature_labels_summary.csv`: Summary table for blog post
- `feature_explanations_data.json`: Raw explanation data

## Conclusion

The feature labels reveal a clear pattern of neural specialization during fine-tuning from BERT to FinBERT. The model successfully repurposed general-purpose features to become domain-specific financial specialists, with dramatic improvements in activation levels and specialization patterns. This demonstrates the effectiveness of fine-tuning in creating domain-adapted neural representations.
