# InterpUseCases: AI Interpretability Research Collection

A comprehensive collection of AI interpretability research use cases, demonstrating advanced techniques for understanding neural network behavior and feature evolution.

## üìÅ **Available Use Cases**

### **UseCase_BERTvsFinBERT**
*Neural Feature Evolution in Domain Adaptation: A Comprehensive Analysis of BERT to FinBERT Fine-tuning*

**Description**: This use case presents a complete analysis of how neural features evolve during fine-tuning from BERT to FinBERT. Using Sparse Autoencoders (SAEs), comprehensive feature comparison, and automated neural interpretation, we reveal the systematic transformation of neural representations during domain adaptation.

**Key Features**:
- Complete SAE training pipeline for BERT and FinBERT
- Comprehensive feature comparison across 200 neural features
- Automated feature interpretation using Delphi and Llama 3.1 8B
- Activation delta analysis revealing dramatic feature transformations
- Professional research blog post with methodology and findings

**Files**: 17 files organized in 5 research stages
- Training scripts and SAE configuration
- Feature analysis and comparison tools
- Neural interpretation and labeling pipeline
- Complete documentation and visualizations

**Repository**: [UseCase_BERTvsFinBERT/](UseCase_BERTvsFinBERT/)

## üéØ **Research Impact**

This collection demonstrates:
1. **Systematic neural feature evolution** during fine-tuning
2. **Intuitive feature specializations** that align with domain requirements
3. **Mathematical regularity** in activation deltas and domain relevance
4. **Interpretable transformations** that can be described in natural language

## üîß **Technical Stack**

- **PyTorch**: Deep learning framework
- **Transformers**: HuggingFace model library
- **Delphi**: SAE auto-interpretation library
- **Llama 3.1 8B**: Large language model for feature interpretation
- **WandB**: Training monitoring and experiment tracking

## üìà **Future Use Cases**

This repository will continue to grow with additional interpretability research:
- Cross-domain feature evolution analysis
- Temporal feature tracking during training
- Architectural comparison studies
- Intervention and ablation studies

## üìù **Citation**

If you use this research or code, please cite:

```
Neural Feature Evolution in Domain Adaptation: A Comprehensive Analysis of BERT to FinBERT Fine-tuning
```

## ü§ù **Contributing**

We welcome contributions of new interpretability use cases. Please ensure:
- Complete code and documentation
- Reproducible research methodology
- Clear file organization
- Comprehensive README

---

*Advancing AI interpretability through systematic research and open collaboration.*
