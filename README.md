# InterpUseCases: AI Interpretability Research Collection

A comprehensive collection of AI interpretability research use cases, demonstrating advanced techniques for understanding neural network behavior and feature evolution.

## üìÅ **Available Use Cases**

### **UseCase_BERTvsFinBERT**
*Neural Feature Evolution in Domain Adaptation: A Comprehensive Analysis of BERT to FinBERT Fine-tuning*

This use case presents a complete analysis of how neural features evolve during fine-tuning from BERT to FinBERT. Using Sparse Autoencoders (SAEs), comprehensive feature comparison, and automated neural interpretation, we reveal the systematic transformation of neural representations during domain adaptation. The research demonstrates systematic neural feature evolution during fine-tuning, with intuitive feature specializations that align with domain requirements and mathematical regularity in activation deltas.

**Key Features**: Complete SAE training pipeline, comprehensive feature comparison across 200 neural features, automated feature interpretation using Delphi and Llama 3.1 8B, activation delta analysis, and professional research documentation.

### **UseCase_Trading**
*Decoding Financial Intelligence: How AI Features Drive Trading Strategy Performance*

This use case demonstrates how domain-specific fine-tuning affects feature representations in language models for financial applications. Using Sparse Autoencoders (SAEs), we extract interpretable features from BERT and FinBERT models to understand how financial fine-tuning creates specialized features that can predict market movements and price changes. The research identifies key financial features that show dramatic improvements in FinBERT compared to BERT, with backtesting results showing 554% total return and 65% win rate.

**Key Features**: Financial feature extraction and analysis, trading strategy development, comprehensive backtesting with exceptional performance metrics, systematic trading framework, and market prediction capabilities.

## üîß **Technical Stack**

- **PyTorch**: Deep learning framework
- **Transformers**: HuggingFace model library
- **Delphi**: SAE auto-interpretation library
- **Llama 3.1 8B**: Large language model for feature interpretation
- **WandB**: Training monitoring and experiment tracking

---

*Advancing AI interpretability through systematic research and open collaboration.*
